{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AVA_Image_Binary_Classification_aumentaions_mod_debuged.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fdsig/A-Lamp/blob/master/AVA_Image_Binary_Classification_aumentaions_mod_debuged.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHXo91Mw8V0K"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import random\n",
        "from shutil import copyfile\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import io\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKiSj0Slj9Hm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JeGrGNDAiM1"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBlYifiN9PVa",
        "outputId": "dc91a7ce-0e25-4359-f3cd-5c5b5dd5345a"
      },
      "source": [
        "\n",
        "def run_process(process = None, command = None):\n",
        "    print(command)\n",
        "    logname = process+'.log'\n",
        "    env = os.environ.copy()\n",
        "    with io.open(logname, 'wb') as writer, io.open(logname, 'rb', 1) as reader:\n",
        "        process = subprocess.Popen(command, stdout=writer, shell=True, env=env)\n",
        "        while process.poll() is None:\n",
        "            sys.stdout.write(reader.read())\n",
        "        # Read the remaining\n",
        "        sys.stdout.write(reader.read())\n",
        "\n",
        "## to innitialize \n",
        "depend = [ \n",
        "                'torch==1.7.0', 'torchvision==0.8.1', 'timm==0.3.2', \n",
        "                'timm==0.3.2', 'albumentations==0.4.6'\n",
        "                ]\n",
        "for dep in depend:\n",
        "    run_process(command='pip install '+dep, process = dep.split('==')[0])\n",
        "\n",
        "cleanup = False\n",
        "if cleanup:\n",
        "    current = [fid for fid in os.scandir() if os.path.isfile(fid)]\n",
        "    for i in current:\n",
        "        os.system('rm -rf '+i.name)\n",
        "\n",
        "\n",
        "#!git clone https://github.com/fdsig/convit.git\n",
        "\n",
        "#!git clone https://github.com/facebookresearch/convit.git\n",
        "repositories = ['https://github.com/fdsig/convit.git',\n",
        "                ' https://github.com/fdsig/image_utils',\n",
        "                'https://github.com/fdsig/A-Lamp']\n",
        "for repo in repositories:\n",
        "    run_process(command='git clone '+repo, process=repo.split('/')[-1])\n",
        "\n",
        "convit_fids = [fid for fid in os.scandir('convit/')]\n",
        "other_fids = [fid for fid in os.scandir('image_utils/')]\n",
        "for fid in convit_fids+other_fids:\n",
        "    shutil.move(fid.path,fid.name)\n",
        "os.system(\n",
        "    'rm convit && rm image_utils && rm -rf convit &&\\\n",
        "     rm -rf MPADA && rm -rf image_utils')\n",
        "\n",
        "import image_getter\n",
        "pull = image_getter.Get_Ava()\n",
        "pull.parse_urls()\n",
        "pull.google_getter()\n",
        "pull.ava_txt()\n",
        "pull.download_ava_files(own_drive=True, \n",
        "                        download=True, \n",
        "                        full=True, \n",
        "                        clear_current=False)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip install torch==1.7.0\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "pip install torchvision==0.8.1\n",
            "Requirement already satisfied: torchvision==0.8.1 in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.7.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (3.7.4.3)\n",
            "pip install timm==0.3.2\n",
            "Requirement already satisfied: timm==0.3.2 in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from timm==0.3.2) (1.7.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.3.2) (0.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (0.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.3.2) (7.1.2)\n",
            "pip install timm==0.3.2\n",
            "Requirement already satisfied: timm==0.3.2 in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.3.2) (0.8.1)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from timm==0.3.2) (1.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (0.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.3.2) (7.1.2)\n",
            "pip install albumentations==0.4.6\n",
            "Requirement already satisfied: albumentations==0.4.6 in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.7.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.16.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "git clone https://github.com/fdsig/convit.git\n",
            "git clone  https://github.com/fdsig/image_utils\n",
            "git clone https://github.com/fdsig/A-Lamp\n",
            "https://drive.google.com/file/d/1YtU0m8cf2qgYcSpcPqlSz2GxO7wowu6W/view?usp=sharing\n",
            "\n",
            "Downloading 1YtU0m8cf2qgYcSpcPqlSz2GxO7wowu6W into ./batch_meta//ava_files_urls.txt... Done.\n",
            "\n",
            " The files are : ./batch_meta/ava_files_urls.txt\n",
            "File IDs have sucessfully been obtaniend and now in content/batch_meta/\n",
            "['1-9PbytN2awBviMP4Br8b4puhzFbUmOg2', '1-TcM8ZitdD-8yxnOlWDYcAIjszxDF5nH', '10hfdjtZgStNXMOYynLoIxlhiaItlAUQ4', '168mr0mkR6_5S5FoBkbzvUw8ulf-17D34', '16JJKoBivo0NUCcA_y2ueX2E0qFzWost7', '18ZMIqTlpfe7bm2cc6mgSkzfsxsmkeSTn', '1EimTfOAOnAsWLyzOESWVstKUcMJ6Ofqa', '1FRkogxsjjzaKumr-xYIp9rL_cLT01TR-', '1JkMJUIAyG3rn5eJ6VX8X5Z4Qq47UFqOi', '1KICR4a-a74aX6mSv9aAD3iXHV2n8vOtg', '1KQfOsOE1I5piQvEaVigYjw6do9Wn3Voz', '1M681Etlo_pot-p61f-wr8Uqf1J62XmuU', '1MifQhi1UJA255ulGYXz-_mWshDWdxrlv', '1NCJNl0gDHBC_cr-G026jIVrtrHgHcb62', '1NU2G7-qIJfg8OOB1KP0cZJ68arbrizJ-', '1NhkdKK5R1Cu-jg6VVMVCzKd9rFXXC9F_', '1OqB-CbF5iKqxgALFnqD6fOtILU0ow9vT', '1U1EvkK0NYlpWDZhRtMX5JzsKhSMO7iy2', '1UdGR02Be64mzuX276xlg--qvpiBa_jpL', '1W7cGe05y7FyB0yqvGiMnFAnGXpiSo1Cl', '1WXhlWVc_WX5GXLkyOhkHhS8kwxi9ko_7', '1_IO7KTXxV4xyOUgM-VXb_GEPKrI3ECJn', '1a-uagqogzPmqkl0rjs0Q9Hm7JvXpbSLW', '1aCT4i_hMrjjzcKydcASWqK3TdcrB6u6v', '1aDe0jAjUDT-USWSiGjv1ayR9-zG-SwRF', '1c0Hv200J_zqLKWsSbRt_xFM3LylD-R8X', '1cFFxbQoSfLKtIKiMvJ785Yc0zeL1yFMa', '1gkm9q34SjZx8qfm5SOMQv01Bus39Vwaj', '1iGaCq4QanFmgbXzoT0K3kRWfR5IsQJKV', '1iHOaAu9JAva0ZtqD2QfJ9TlXmlfIU37d', '1l-8KfidQf_CTiHo-VpLkZw1TJjIGmkA0', '1l-fRPtT306qOaWDvhs4lHOp541jspqvA', '1pPlo0U5lFCuMWd6K40MyBjeoq6Bo5OOq', '1rWpnzewbc5HIKg1fLAw_jbfHITrkyLAs', '1sJ9vxvHfhWXPW45rqi_x2XfQ8IqLBXE3', '1tjVV1zepAbVgBqbPDAPqZwERwq9PFxO0', '1upX78_Xv2dhSRSNTtCMJasQRBT3nkz3B', '1v8vTG_bHYIpsk14Suk4FvVpxqn2_GcsX', '1xsFTf5mxOiNhVGme0ZyR4GUWDGIYSSJ4', '1yCr6MrFo-REOnD5qoJXlHtuBUTglpTsB', '1z9pHSimnfIbuQv4-bKX30zf3USZ17COi', '1zXMuAkEcZgIIgmqQH8VsgjusKu-rl3OD', '1zo_qzNfi8b9OONqnerDtzBbFup_faDm5', '1zuM028Jul5OpE1PARIBRXIicvT2WMEZt']\n",
            "{'own_drive': True, 'download': True, 'full': True, 'clear_current': False}\n",
            "no files cleared if re running this \n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u001b[38;2;255;105;180m██████████\u001b[0m| 44/44 [12:28<00:00, 17.00s/it]\n",
            "100%|██████████| 255508/255508 [00:10<00:00, 24188.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 already exist \n",
            " all files = 255508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "45it [00:00, 5105.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "255508 [<DirEntry 'images'>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akUmqg7hASMQ"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSIfT5Ov2dU3"
      },
      "source": [
        "\n",
        "class Square:\n",
        "    def __call__(self,img): \n",
        "            dims = np.array(img.size)\n",
        "            m_x = dims[[dims.argmax()]][0]\n",
        "            y_axis_pad = int(m_x-dims[1])//2 ;x_axis_pad = int(m_x-dims[0])//2\n",
        "            y_axis_pad+=1;x_axis_pad+=1\n",
        "            pad = (x_axis_pad, y_axis_pad, x_axis_pad, y_axis_pad)\n",
        "            return torchvision.transforms.functional.pad(img,pad,0,'constant')\n",
        "\n",
        "train_reflect_tansform = A.Compose([\n",
        "            A.augmentations.transforms.LongestMaxSize(max_size=256),\n",
        "            A.augmentations.transforms.PadIfNeeded(256,256,  always_apply=True),\n",
        "            ]) \n",
        "train_transforms = transforms.Compose(\n",
        "    [\n",
        "        Square(),\n",
        "     transforms.Resize((256,256)),\n",
        "    ]\n",
        ")\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ToAwVLt28hE"
      },
      "source": [
        "def meta_process():\n",
        "    df = pd.read_csv('ava_meta_with_int_id_230721.csv')\n",
        "    y_gt = df['mos_float'].values\n",
        "    ids = df['ID'].values\n",
        "    all_ims = len(list(os.scandir('Images/images')))\n",
        "    print()\n",
        "    print(f' Initial Fids {len(ids)}')\n",
        "    y_gt_std, y_gt_mean = np.std(y_gt, axis = 0), np.mean(y_gt, axis = 0)\n",
        "    exclude_below = y_gt_mean-y_gt_std*4\n",
        "    exclude_above = y_gt_mean+y_gt_std*4\n",
        "    ids = ids[np.argwhere(y_gt>=exclude_below)].ravel()\n",
        "    y_gt = y_gt[np.argwhere(y_gt>=exclude_below)].ravel()\n",
        "    print(f' number image after outliers {len(y_gt)}')\n",
        "    ids = ids[np.argwhere(y_gt<=exclude_above)].ravel()\n",
        "    y_gt = y_gt[np.argwhere(y_gt<=exclude_above)].ravel()\n",
        "    print(len(ids),len(y_gt))\n",
        "    ids_low = ids[np.argwhere(y_gt<4.99)].ravel().astype(int)\n",
        "    ids_high = ids[np.argwhere(y_gt>5.01)].ravel().astype(int)\n",
        "    to_include = np.concatenate((ids_low,ids_high), axis=0)\n",
        "    n_include = len(to_include)\n",
        "    f' number of images to include {n_include} excluded {all_ims-n_include}'\n",
        "    return df[df['ID'].isin(to_include)]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eus9hc9hB9FG"
      },
      "source": [
        "class Pre_pipe:\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.subpatch=False, \n",
        "        self.move=False\n",
        "        self.box_n = False\n",
        "        self.src = 'Images/images/'\n",
        "        self.dest = 'data/'\n",
        "        self.miss = None\n",
        "        #create desitination paths\n",
        "        self.test_train = ['train/','test/', 'val/']\n",
        "        self.classes = ['class_1/','class_0/']\n",
        "        self.create_dict()\n",
        "    \n",
        "    def destination(self):\n",
        "        for i in self.test_train:\n",
        "            for j in self.classes:\n",
        "                os.makedirs(self.dest+i+j, exist_ok=True)\n",
        "                print(f'made dir = {self.dest+i+j}')\n",
        "        \n",
        "    def create_dict(self):\n",
        "        self.destination()\n",
        "        train_dir,test_dir,val_dir = self.test_train\n",
        "        class_1, class_0 = self.classes \n",
        "        src_did = self.src\n",
        "        df = meta_process()\n",
        "        y_g = df[['threshold','ID','set']].to_dict('index')\n",
        "        y_g_dict = {\n",
        "            str(y_g[pair_key]['ID']):y_g[pair_key]for pair_key in y_g\n",
        "            }\n",
        "        y_g_dict = {\n",
        "            key:\n",
        "            {**y_g_dict[key],**{'src':src_did+key+'.jpg'}} \n",
        "             for key in y_g_dict\n",
        "             } \n",
        "        self.y_g_dict = {\n",
        "            key:{**y_g_dict[key], **{'dest':class_1}} \n",
        "                 if y_g_dict[key]['threshold']==1 \n",
        "                 else {**y_g_dict[key], **{'dest':class_0}} \n",
        "                 for key in y_g_dict\n",
        "                 }\n",
        "        dict_n = len(self.y_g_dict)                 \n",
        "        print(f' Images Dictionary has meta data on {len(self.y_g_dict)} images')\n",
        "        \n",
        "\n",
        "    def copy(self, subpatch=None, move=None):\n",
        "        \n",
        "        if not self.move and self.subpatch:\n",
        "            print('exected')\n",
        "            box = f'_patch_{self.box_n}{ext}'    \n",
        "            if self.miss:\n",
        "                miss_copy = (k \n",
        "                    for i in os.scandir('data/') \n",
        "                    for j in os.scandir(i) \n",
        "                    for k in os.scandir(j))\n",
        "                for fid in tqdm(miss_copy):\n",
        "                    shutil.move(fid.path,self.root+fid.name)\n",
        "                \n",
        "            ##some process\n",
        "            for key in tqdm(y_g_dict):\n",
        "                \n",
        "                if y_g_dict[key]['set'] == 'training':\n",
        "                    self.y_g_dict[key]['fid']=(\n",
        "                        root+train_dir+y_g_dict[key]['dest']+key+box\n",
        "                        )\n",
        "                elif y_g_dict[key]['set'] == 'test':\n",
        "                    self.y_g_dict[key]['fid']=(\n",
        "                        root+test_dir+y_g_dict[key]['dest']+key+box\n",
        "                        )\n",
        "                else:\n",
        "                    self.y_g_dict[key]['fid']=(\n",
        "                        root+val_dir+y_g_dict[key]['dest']+key+box\n",
        "                        )\n",
        "                \n",
        "                if not os.path.isfile(self.y_g_dict[key]['fid']): \n",
        "                    print('exected')\n",
        "                    src = y_g_dict[key]['src']\n",
        "                    bbox = self.y_g_dict[key]['BBoxes'][self.box_n]\n",
        "                    self.img = read(src)[bbox[1]:bbox[3], bbox[0]:bbox[2],:]\n",
        "\n",
        "                    try:\n",
        "                        cv2.imwrite(self.y_g_dict[key]['fid'],self.img)\n",
        "                    except:\n",
        "                        print(self.y_g_dict[key]['fid'], 'not saved')\n",
        "    \n",
        "    def augment(self,  augment_type=None):\n",
        "        read = lambda fid_: cv2.cvtColor(cv2.imread(fid_), cv2.COLOR_BGR2RGB)\n",
        "        y_g_dict = self.y_g_dict\n",
        "        root = self.dest\n",
        "        ext = '.jpg'\n",
        "        train_dir,test_dir,val_dir = self.test_train\n",
        "        for key in tqdm(y_g_dict):\n",
        "            \n",
        "            if augment_type == 'zero_pad':\n",
        "                img = read(y_g_dict[key]['src'])\n",
        "                img = train_transforms(Image.fromarray(img))\n",
        "                img = np.asarray(img).astype('uint8')\n",
        "            elif augment_type == 'reflect':\n",
        "                img = read(y_g_dict[key]['src'])\n",
        "                img = train_reflect_tansform(image=img)['image']\n",
        "\n",
        "            if y_g_dict[key]['set'] == 'training':\n",
        "                y_g_dict[key]['fid']=(\n",
        "                    root+train_dir+y_g_dict[key]['dest']+augment_type+key+ext\n",
        "                    )\n",
        "                cv2.imwrite(y_g_dict[key]['fid'],img)\n",
        "            elif y_g_dict[key]['set'] == 'test':\n",
        "                y_g_dict[key]['fid']=(\n",
        "                    root+test_dir+y_g_dict[key]['dest']+augment_type+key+ext\n",
        "                    )\n",
        "                cv2.imwrite(y_g_dict[key]['fid'],img)\n",
        "            else:\n",
        "                y_g_dict[key]['fid']=(\n",
        "                    root+val_dir+y_g_dict[key]['dest']+augment_type+key+ext\n",
        "                    )\n",
        "                cv2.imwrite(y_g_dict[key]['fid'],img)\n",
        "        \n",
        "    def undo(self):\n",
        "        fids = [k for i in os.scandir('data/') \n",
        "                  for j in os.scandir(i) \n",
        "                  for k in os.scandir(j)]\n",
        "        \n",
        "        dest = 'Images/images/'\n",
        "        all_ims = len(list(os.scandir(dest)))\n",
        "        print(f'there are {all_ims} ins Source')\n",
        "        for i in fids:\n",
        "            shutil.move(i.path,dest+i.name )\n",
        "        fids = [k for i in os.scandir('data/') \n",
        "                  for j in os.scandir(i) \n",
        "                  for k in os.scandir(j)]\n",
        "        all_ims = len(list(os.scandir(dest)))\n",
        "        print(f'there are {all_ims} ins Source')\n",
        "        \n",
        "\n",
        "                \n",
        "                \n",
        "    def get_patches(self):\n",
        "        self.subpach = True\n",
        "        bbox_path = '/content/A-Lamp/multi_patch_subnet/adaptive_patch_selection/output-split'\n",
        "        batches_dir = list(os.walk(bbox_path))[0][1]\n",
        "        bbox_files = {i[-2:]:[j.path for j in os.scandir(bbox_path+'/'+i)] for i in batches_dir}\n",
        "        keys = list(bbox_files.keys())\n",
        "        for key in tqdm(keys):\n",
        "            for fl in bbox_files[key]:\n",
        "                with open(fl, 'rb') as pk:\n",
        "                    if 'df' not in locals():\n",
        "                        df = pd.read_pickle(pk)\n",
        "                    else:\n",
        "                        df = df.append(pd.read_pickle(pk))\n",
        "                    \n",
        "        boxes_dict = {\n",
        "            k.split('/')[-1].split('.')[0]:{'BBoxes':v} \n",
        "            for k,v in zip(df['Filename'],df['BBoxes']) \n",
        "            }\n",
        "\n",
        "        self.y_g_dict = {\n",
        "            key:{**self.y_g_dict[key],**boxes_dict[key]} \n",
        "            for key in self.y_g_dict \n",
        "            if key in boxes_dict\n",
        "            }\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMC0hMV8GkAo"
      },
      "source": [
        "#pre = Pre_pipe()\n",
        "pre_args = ['reflect','zero_pad']\n",
        "import copy \n",
        "import shutil\n",
        "# consider using from pathlib import Path to adress multipl +'/' in code\n",
        "class Implement:\n",
        "    def __init__(self):\n",
        "        #self.pre = Pre_pipe()\n",
        "        self.convit_args = [\n",
        "                'python main.py',\n",
        "                '--pretrained', \n",
        "                '--repeated-aug',\n",
        "                '--batch-size 260' ,\n",
        "                '--data-path data/',\n",
        "                '--nb_classes 2', \n",
        "                '--nb_classes_pre 1000', \n",
        "                '--input-size 224',  \n",
        "                '--embed_dim 48', \n",
        "                '--world_size 1', \n",
        "                '--epochs 10',\n",
        "                '--warmup-epochs 5',\n",
        "                '--cooldown-epochs 0',\n",
        "                '--lr-noise-pct 0.5',\n",
        "                '--lr-noise-std 0.5',\n",
        "                '--decay-epochs 0',\n",
        "                '--pre_save',\n",
        "                '--pre_save_path drive/MyDrive/0.AVA/results/convt_tiny_zero_stt/', \n",
        "                '--resume drive/MyDrive/0.AVA/results/convt_tiny_zero_stt/checkpoint.pth'\n",
        "\n",
        "                ]\n",
        "        self.fid = 'drive/MyDrive/0.AVA/results/grids'\n",
        "    def augment(self):\n",
        "        Pre_pipe().augment(augment_type='reflect')\n",
        "\n",
        "    def grid(self):\n",
        "        args = {\"--color-jitter\" : np.round(np.linspace(.2,.5,3),2),\n",
        "        '--locality_strength': np.round(np.linspace(0.5,2,6),2),\n",
        "        '--lr': np.round(np.linspace(0.0001,0.0003,3),5)}\n",
        "        cat, local, lr = (args[i] for i in args)\n",
        "        search_space = [[\n",
        "        cat[i],local[j],lr[m]] \n",
        "        for i in range(len(cat)) \n",
        "        for j in range(len(local))\n",
        "        for m in range(len(lr))]\n",
        "\n",
        "        print(f'Searching {len(search_space)} Unique Paramiter Combinations ')\n",
        "        \n",
        "        return [' '.join([key+' '+str(arg) for key, arg in zip(args,i)]) for i in search_space]\n",
        "    \n",
        "    \n",
        "    def clear_cach(self):\n",
        "        chk_dir = '/root/.cache/torch/hub/checkpoints/'\n",
        "        if os.path.isdir(chk_dir):\n",
        "            for chkpnt in os.scandir(chk_dir):\n",
        "                print(f'rm\"ing {chkpnt.path}')\n",
        "                os.system(f'rm {chkpnt.path}')\n",
        "\n",
        "\n",
        "    def run(self,compare_size=None,grid_search=None, convit_args=None, ):\n",
        "        pre_args = ['reflect','zero_pad']\n",
        "        model_args = [ '--model convit_tiny', '--model convit_small', '--model convit_base']\n",
        "        if compare_size:\n",
        "            for arg in pre_args:\n",
        "                os.system('rm -rf data/')\n",
        "                pre.destination()\n",
        "                pre.move == True\n",
        "                pre.miss == False\n",
        "                print(f'Augmenting with: {arg}')\n",
        "                pre.augment(augment_type=arg)\n",
        "                for size in model_args:\n",
        "                    self.convit_args.insert(4, '--output_dir drive/MyDrive/0.AVA/results/'+arg+size.split(' ')[-1])\n",
        "                    self.convit_args.insert(3,size)\n",
        "                    command = ' '.join(self.convit_args)\n",
        "                    print(f'Runing Process with Args : {self.convit_args}')\n",
        "                    run_process(process='convit', command=command)\n",
        "                    convit_args.pop(3);convit_args.pop(4)\n",
        "        \n",
        "\n",
        "        elif grid_search:\n",
        "            \n",
        "            grid = self.grid()\n",
        "            self.convit_args.insert(3,'--model convit_tiny')\n",
        "            convit_args = self.convit_args\n",
        "            args_check = copy.deepcopy(convit_args)\n",
        "            print(convit_args)\n",
        "            \n",
        "            for idx, grid_i in enumerate(grid):\n",
        "                #append hyper params args\n",
        "                convit_args.append(grid_i)\n",
        "                #checks for cached model weights\n",
        "                # to mitigate data leak if subprocess code \n",
        "                # reloading model on weights grid n -=1(previous grid). \n",
        "                self.clear_cach()\n",
        "\n",
        "                print('\\n',idx,grid_i)\n",
        "                #subprocess directory \n",
        "                dir_arg = '--output_dir '\n",
        "                \n",
        "                grids_dir = 'drive/MyDrive/0.AVA/results/grids_2/'\n",
        "                self.dir =grids_dir\n",
        "                grid_n = 'grid_'+ str(idx)\n",
        "\n",
        "                model_dir = grids_dir + grid_n + '/'\n",
        "                convit_args.insert(4,dir_arg+ model_dir)\n",
        "                print(f'model args including model dir is{\"%\"*20} {convit_args}')\n",
        "\n",
        "                resume_from_fid = 'drive/MyDrive/0.AVA/results/convt_tiny_zero_stt/'\n",
        "\n",
        "                # file in directory of grid_i path names\n",
        "                checkpoint,log = 'checkpoint.pth','log.txt'\n",
        "                resume_from = resume_from_fid+checkpoint\n",
        "               \n",
        "                # for restarting from logfile\n",
        "                log_fid = resume_from_fid+log\n",
        "\n",
        "                # check if chepoint file exists\n",
        "                if os.path.isfile(resume_from):\n",
        "                    self.clear_cach()\n",
        "                    cmd = '--resume '\n",
        "                    print(f'resuming from {resume_from}')\n",
        "                    convit_args.insert(4,cmd+resume_from)\n",
        "                    # check if log file to get n epochs\n",
        "                    if os.path.isfile(log_fid):\n",
        "                        with open(log_fid, 'r') as fid:\n",
        "                            n_epochs = len(fid.readlines())\n",
        "                    else:\n",
        "                        n_epochs = 0\n",
        "\n",
        "                    if n_epochs<=10:\n",
        "                        n_epochs-=1\n",
        "                        print('n_epochs',n_epochs)\n",
        "                        start = \"--start_epoch \"+str(n_epochs)\n",
        "                        convit_args.insert(4,start)\n",
        "                        #joins suprocess args list to string\n",
        "                        # for subprocess args parser. \n",
        "                        command = ' '.join(self.convit_args)\n",
        "                        print(f'Running: {command}')\n",
        "                        # runs subprosess \n",
        "                        run_process(process='covit_gird_'+str(idx), \n",
        "                                    command=command)\n",
        "                        self.clear_cach()\n",
        "                        \n",
        "                        convit_args.pop(4);convit_args.pop(4)\n",
        "                    \n",
        "                    elif n_epochs>=10:\n",
        "                        print('passing as already trained', '*'*20)\n",
        "                        convit_args.pop(4)\n",
        "                    else:\n",
        "                        # runs code as normal withot resum \n",
        "                        print('running as normal'* 30, '\\n')\n",
        "                        print(convit_args)\n",
        "                        ## insert resume from path of base(zero train)\n",
        "                        \n",
        "                        convit_args.pop(4)\n",
        "                        print(convit_args)\n",
        "        \n",
        "                        command = ' '.join(self.convit_args)\n",
        "                        print(f'running: {command}')\n",
        "                        run_process(process='covit_gird_'+str(idx), \n",
        "                                    command=command)\n",
        "                        self.clear_cach()\n",
        "\n",
        "\n",
        "                else:\n",
        "                    command = ' '.join(self.convit_args)\n",
        "                    print(f'running: {command}')\n",
        "                    run_process(process='covit_gird_'+str(idx), command=command)\n",
        "                    self.clear_cach()\n",
        "                convit_args.pop(4)\n",
        "\n",
        "\n",
        "                #rmoves grid_i params\n",
        "                convit_args.pop()\n",
        "                # checks if params have been reset(for debugging)\n",
        "                print(convit_args == args_check)\n",
        "    def get_metrics(self):\n",
        "        ''' for evaluating paramiter search (copies log.txt ans saves idx'd version'''\n",
        "        #resolve grid = file name (where in code???) \n",
        "        logs = [\n",
        "         (j,_idx) for _idx,i in enumerate(os.scandir(self.dir)) \n",
        "            for idx,j in enumerate(os.scandir(i)) if 'log.txt' in j.name\n",
        "            ]\n",
        "        for posix,idx in logs:\n",
        "            path = '/'.join(posix.path.split('/')[:-2])+'/grid_all_logs/'\n",
        "            os.makedirs(path,exist_ok=True)\n",
        "            name,ext = posix.name.split('.')\n",
        "            new_name = name+str(idx)+'.'+ext\n",
        "            new_fid = path+new_name\n",
        "            #print(new_fid)\n",
        "            shutil.copy(posix,new_fid)\n",
        "        \n",
        "    \n",
        "\n",
        "            \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKrcPOodzdry"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9-8YDsecXpI",
        "outputId": "39844aa8-0903-4c9e-f549-ed564abc3c32"
      },
      "source": [
        "Implement().augment()\n",
        "Implement().run(grid_search=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "made dir = data/train/class_1/\n",
            "made dir = data/train/class_0/\n",
            "made dir = data/test/class_1/\n",
            "made dir = data/test/class_0/\n",
            "made dir = data/val/class_1/\n",
            "made dir = data/val/class_0/\n",
            "\n",
            " Initial Fids 255502\n",
            " number image after outliers 255411\n",
            "255403 255403\n",
            " Images Dictionary has meta data on 253030 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 8546/253030 [01:23<34:12, 119.13it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gopcuhOnreuV"
      },
      "source": [
        " chk_dir = '/root/.cache/torch/hub/checkpoints/'\n",
        "\n",
        "if os.path.isdir(chk_dir):\n",
        "    for chkpnt in os.scandir(chk_dir):\n",
        "        print(f'rm\"ing {chkpnt.path}')\n",
        "        os.system(f'rm {chkpnt.path}')\n",
        "\n",
        "!python main.py --pre_save --pre_save_path drive/MyDrive/0.AVA/results/convt_tiny_zero_stt/  --pretrained --batch-size 260 --model convit_tiny --epochs 20 --output_dir drive/MyDrive/0.AVA/results/convt_tiny_zero_stt/ --data-path data/ --nb_classes 2 --nb_classes_pre 1000 --input-size 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwrVQR1Px53W"
      },
      "source": [
        "aa='rand-m9-mstd0.5-inc1', \n",
        "batch_size=50, \n",
        "clip_grad=None, \n",
        "color_jitter=0.4, \n",
        "cooldown_epochs=10, \n",
        "cutmix=1.0, \n",
        "cutmix_minmax=None, \n",
        "data_path='data/', \n",
        "data_set='IMNET', \n",
        "decay_epochs=30, \n",
        "decay_rate=0.1, \n",
        "device='cuda', \n",
        "dist_url='env://', \n",
        "distributed=False, \n",
        "drop=0.0, \n",
        "drop_block=None, \n",
        "drop_path=0.1, \n",
        "embed_dim=48, \n",
        "epochs=20, \n",
        "eval=False, \n",
        "inat_category='supercategory', \n",
        "input_size=224, \n",
        "local_up_to_layer=10, \n",
        "locality_strength=4.0, \n",
        "lr=0.0005, \n",
        "lr_noise=None, \n",
        "lr_noise_pct=0.67, \n",
        "lr_noise_std=1.0, \n",
        "min_lr=1e-05, \n",
        "mixup=0.8, \n",
        "mixup_mode='batch', \n",
        "mixup_prob=1.0, \n",
        "mixup_switch_prob=0.5, \n",
        "model='convit_base', \n",
        "model_ema=False, \n",
        "model_ema_decay=0.99996, \n",
        "model_ema_force_cpu=False, \n",
        "momentum=0.9, \n",
        "nb_classes=2, \n",
        "nb_classes_pre=1000, \n",
        "num_workers=10, \n",
        "opt='adamw', \n",
        "opt_betas=None, \n",
        "opt_eps=1e-08, \n",
        "output_dir='drive/MyDrive/0.AVA/results/zero_padconvit_base', \n",
        "patience_epochs=10, \n",
        "pin_mem=True, \n",
        "pretrained=True, \n",
        "recount=1, \n",
        "remode='pixel', \n",
        "repeated_aug=True, \n",
        "\n",
        "resplit=False, \n",
        "resume='', \n",
        "sampling_ratio=1.0, \n",
        "save_every=None, \n",
        "sched='cosine', \n",
        "seed=0, \n",
        "smoothing=0.1, \n",
        "start_epoch=0, \n",
        "train_interpolation='bicubic', \n",
        "warmup_epochs=5, \n",
        "warmup_lr=1e-06, \n",
        "weight_decay=0.05, \n",
        "world_size=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY8czAFO25tX"
      },
      "source": [
        "'''boxes = [0,1,2,3,4]\n",
        "for box in boxes:\n",
        "    os.system('rm -rf data/')\n",
        "    print('data' in [i.name for i in os.scandir('.')])\n",
        "    pre.box_n=box\n",
        "    pre.destination()\n",
        "    print('data' in [i.name for i in os.scandir('.')])\n",
        "    pre.miss = True\n",
        "    pre.copy()\n",
        "    args[4]='--output_dir drive/MyDrive/0.AVA/results/patch_no_'+str(box)\n",
        "    command = ' '.join(args)\n",
        "    fid = list(os.scandir('data/test/class_0/'))[1].path\n",
        "    img = cv2.imread(fid)\n",
        "    plt.imshow(img)\n",
        "    run_process(process = 'convit', command = command)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIlTCd_elv8c"
      },
      "source": [
        " fid_ = pre.y_g_dict[list(pre.y_g_dict.keys())[5]]['src']\n",
        " read = lambda fid_: cv2.cvtColor(cv2.imread(fid_), cv2.COLOR_BGR2RGB)\n",
        " img = read(fid_)\n",
        " zero_pad_array = train_transforms(Image.fromarray(img)).permute(1,2,0)\n",
        " plt.imshow(zero_pad_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8VfCHxxxqDL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}