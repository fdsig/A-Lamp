{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AVA_Image_Binary_Classification_aumentaions_mod_debuged.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fdsig/A-Lamp/blob/master/AVA_Image_Binary_Classification_aumentaions_mod_debuged.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHXo91Mw8V0K"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import random\n",
        "from shutil import copyfile\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import io\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBlYifiN9PVa",
        "outputId": "02e173c2-2c1e-4939-922b-78233dc56c1e"
      },
      "source": [
        "def run_process(process = None, command = None):\n",
        "    print(command)\n",
        "    logname = process+'.log'\n",
        "    env = os.environ.copy()\n",
        "    with io.open(logname, 'wb') as writer, io.open(logname, 'rb', 1) as reader:\n",
        "        process = subprocess.Popen(command, stdout=writer, shell=True, env=env)\n",
        "        while process.poll() is None:\n",
        "            sys.stdout.write(reader.read())\n",
        "        # Read the remaining\n",
        "        sys.stdout.write(reader.read())\n",
        "\n",
        "## to innitialize \n",
        "depend = [ \n",
        "                'torch==1.7.0', 'torchvision==0.8.1', 'timm==0.3.2', \n",
        "                'timm==0.3.2', 'albumentations==0.4.6'\n",
        "                ]\n",
        "for dep in depend:\n",
        "    run_process(command='pip install '+dep, process = dep.split('==')[0])\n",
        "\n",
        "cleanup = True\n",
        "if cleanup:\n",
        "    current = [fid for fid in os.scandir() if 'drive' not in fid.name]\n",
        "    for i in current:\n",
        "        os.system('rm -rf '+i.name)\n",
        "\n",
        "\n",
        "#!git clone https://github.com/fdsig/convit.git\n",
        "\n",
        "#!git clone https://github.com/facebookresearch/convit.git\n",
        "repositories = ['https://github.com/mawady/convit.git',\n",
        "                ' https://github.com/fdsig/image_utils',\n",
        "                'https://github.com/fdsig/A-Lamp']\n",
        "for repo in repositories:\n",
        "    run_process(command='git clone '+repo, process=repo.split('/')[-1])\n",
        "\n",
        "convit_fids = [fid for fid in os.scandir('convit/')]\n",
        "other_fids = [fid for fid in os.scandir('image_utils/')]\n",
        "for fid in convit_fids+other_fids:\n",
        "    shutil.move(fid.path,fid.name)\n",
        "os.system(\n",
        "    'rm convit && rm image_utils && rm -rf convit &&\\\n",
        "     rm -rf MPADA && rm -rf image_utils')\n",
        "\n",
        "import image_getter\n",
        "pull = image_getter.Get_Ava()\n",
        "pull.parse_urls()\n",
        "pull.google_getter()\n",
        "pull.ava_txt()\n",
        "pull.download_ava_files(own_drive=True, \n",
        "                        download=True, \n",
        "                        full=True, \n",
        "                        clear_current=False)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip install torch==1.7.0\n",
            "Collecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "      Successfully uninstalled torch-1.9.0+cu111\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n",
            "pip install torchvision==0.8.1\n",
            "Collecting torchvision==0.8.1\n",
            "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.19.5)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.7.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu111\n",
            "    Uninstalling torchvision-0.10.0+cu111:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu111\n",
            "Successfully installed torchvision-0.8.1\n",
            "pip install timm==0.3.2\n",
            "Collecting timm==0.3.2\n",
            "  Downloading timm-0.3.2-py3-none-any.whl (244 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.3.2) (0.8.1)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from timm==0.3.2) (1.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (0.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.3.2) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.3.2\n",
            "pip install timm==0.3.2\n",
            "Requirement already satisfied: timm==0.3.2 in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.3.2) (0.8.1)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from timm==0.3.2) (1.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (0.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.3.2) (7.1.2)\n",
            "pip install albumentations==0.4.6\n",
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py): started\n",
            "  Building wheel for albumentations (setup.py): finished with status 'done'\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65172 sha256=efa397832d46332f9155e817ba4ad33a2b04b493f1b93f56604eded93b0e3785\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n",
            "git clone https://github.com/mawady/convit.git\n",
            "git clone  https://github.com/fdsig/image_utils\n",
            "git clone https://github.com/fdsig/A-Lamp\n",
            "Drive not mounted, so nothing to flush and unmount.\n",
            "https://drive.google.com/file/d/1YtU0m8cf2qgYcSpcPqlSz2GxO7wowu6W/view?usp=sharing\n",
            "\n",
            "Downloading 1YtU0m8cf2qgYcSpcPqlSz2GxO7wowu6W into ./batch_meta//ava_files_urls.txt... Done.\n",
            "\n",
            " The files are : ./batch_meta/ava_files_urls.txt\n",
            "File IDs have sucessfully been obtaniend and now in content/batch_meta/\n",
            "['1-9PbytN2awBviMP4Br8b4puhzFbUmOg2', '1-TcM8ZitdD-8yxnOlWDYcAIjszxDF5nH', '10hfdjtZgStNXMOYynLoIxlhiaItlAUQ4', '168mr0mkR6_5S5FoBkbzvUw8ulf-17D34', '16JJKoBivo0NUCcA_y2ueX2E0qFzWost7', '18ZMIqTlpfe7bm2cc6mgSkzfsxsmkeSTn', '1EimTfOAOnAsWLyzOESWVstKUcMJ6Ofqa', '1FRkogxsjjzaKumr-xYIp9rL_cLT01TR-', '1JkMJUIAyG3rn5eJ6VX8X5Z4Qq47UFqOi', '1KICR4a-a74aX6mSv9aAD3iXHV2n8vOtg', '1KQfOsOE1I5piQvEaVigYjw6do9Wn3Voz', '1M681Etlo_pot-p61f-wr8Uqf1J62XmuU', '1MifQhi1UJA255ulGYXz-_mWshDWdxrlv', '1NCJNl0gDHBC_cr-G026jIVrtrHgHcb62', '1NU2G7-qIJfg8OOB1KP0cZJ68arbrizJ-', '1NhkdKK5R1Cu-jg6VVMVCzKd9rFXXC9F_', '1OqB-CbF5iKqxgALFnqD6fOtILU0ow9vT', '1U1EvkK0NYlpWDZhRtMX5JzsKhSMO7iy2', '1UdGR02Be64mzuX276xlg--qvpiBa_jpL', '1W7cGe05y7FyB0yqvGiMnFAnGXpiSo1Cl', '1WXhlWVc_WX5GXLkyOhkHhS8kwxi9ko_7', '1_IO7KTXxV4xyOUgM-VXb_GEPKrI3ECJn', '1a-uagqogzPmqkl0rjs0Q9Hm7JvXpbSLW', '1aCT4i_hMrjjzcKydcASWqK3TdcrB6u6v', '1aDe0jAjUDT-USWSiGjv1ayR9-zG-SwRF', '1c0Hv200J_zqLKWsSbRt_xFM3LylD-R8X', '1cFFxbQoSfLKtIKiMvJ785Yc0zeL1yFMa', '1gkm9q34SjZx8qfm5SOMQv01Bus39Vwaj', '1iGaCq4QanFmgbXzoT0K3kRWfR5IsQJKV', '1iHOaAu9JAva0ZtqD2QfJ9TlXmlfIU37d', '1l-8KfidQf_CTiHo-VpLkZw1TJjIGmkA0', '1l-fRPtT306qOaWDvhs4lHOp541jspqvA', '1pPlo0U5lFCuMWd6K40MyBjeoq6Bo5OOq', '1rWpnzewbc5HIKg1fLAw_jbfHITrkyLAs', '1sJ9vxvHfhWXPW45rqi_x2XfQ8IqLBXE3', '1tjVV1zepAbVgBqbPDAPqZwERwq9PFxO0', '1upX78_Xv2dhSRSNTtCMJasQRBT3nkz3B', '1v8vTG_bHYIpsk14Suk4FvVpxqn2_GcsX', '1xsFTf5mxOiNhVGme0ZyR4GUWDGIYSSJ4', '1yCr6MrFo-REOnD5qoJXlHtuBUTglpTsB', '1z9pHSimnfIbuQv4-bKX30zf3USZ17COi', '1zXMuAkEcZgIIgmqQH8VsgjusKu-rl3OD', '1zo_qzNfi8b9OONqnerDtzBbFup_faDm5', '1zuM028Jul5OpE1PARIBRXIicvT2WMEZt']\n",
            "{'own_drive': True, 'download': True, 'full': True, 'clear_current': False}\n",
            "no files cleared if re running this \n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u001b[38;2;255;105;180m██████████\u001b[0m| 44/44 [12:29<00:00, 17.03s/it]\n",
            "100%|██████████| 255508/255508 [00:10<00:00, 24323.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 already exist \n",
            " all files = 255508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "45it [00:00, 5199.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "255508 [<DirEntry 'images'>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSIfT5Ov2dU3"
      },
      "source": [
        "\n",
        "class Square:\n",
        "    def __call__(self,img): \n",
        "            dims = np.array(img.size)\n",
        "            m_x = dims[[dims.argmax()]][0]\n",
        "            y_axis_pad = int(m_x-dims[1])//2 ;x_axis_pad = int(m_x-dims[0])//2\n",
        "            y_axis_pad+=1;x_axis_pad+=1\n",
        "            pad = (x_axis_pad, y_axis_pad, x_axis_pad, y_axis_pad)\n",
        "            return torchvision.transforms.functional.pad(img,pad,0,'constant')\n",
        "\n",
        "train_reflect_tansform = A.Compose([\n",
        "            A.augmentations.transforms.LongestMaxSize(max_size=256),\n",
        "            A.augmentations.transforms.PadIfNeeded(256,256,  always_apply=True),\n",
        "            ]) \n",
        "train_transforms = transforms.Compose(\n",
        "    [\n",
        "        Square(),\n",
        "     transforms.Resize((256,256)),\n",
        "    ]\n",
        ")\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ToAwVLt28hE"
      },
      "source": [
        "def meta_process():\n",
        "    df = pd.read_csv('ava_meta_with_int_id_230721.csv')\n",
        "    y_gt = df['mos_float'].values\n",
        "    ids = df['ID'].values\n",
        "    print(len(ids))\n",
        "    y_gt_std, y_gt_mean = np.std(y_gt, axis = 0), np.mean(y_gt, axis = 0)\n",
        "    exclude_below = y_gt_mean-y_gt_std*4\n",
        "    exclude_above = y_gt_mean+y_gt_std*4\n",
        "    ids = ids[np.argwhere(y_gt>=exclude_below)].ravel()\n",
        "    y_gt = y_gt[np.argwhere(y_gt>=exclude_below)].ravel()\n",
        "    print(len(y_gt))\n",
        "    ids = ids[np.argwhere(y_gt<=exclude_above)].ravel()\n",
        "    y_gt = y_gt[np.argwhere(y_gt<=exclude_above)].ravel()\n",
        "    print(len(ids),len(y_gt))\n",
        "    ids_low = ids[np.argwhere(y_gt<4.99)].ravel().astype(int)\n",
        "    ids_high = ids[np.argwhere(y_gt>5.01)].ravel().astype(int)\n",
        "    to_include = np.concatenate((ids_low,ids_high), axis=0)\n",
        "    len(to_include)\n",
        "    return df[df['ID'].isin(to_include)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus9hc9hB9FG",
        "outputId": "3b03c2b0-8fe9-47ec-9091-9a182336d9d1"
      },
      "source": [
        "class Pre_pipe:\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.subpatch=False, \n",
        "        self.move=False\n",
        "        self.box_n = False\n",
        "        self.src = 'Images/images/'\n",
        "        self.dest = 'data/'\n",
        "        self.miss = None\n",
        "        #create desitination paths\n",
        "        self.test_train = ['train/','test/', 'val/']\n",
        "        self.classes = ['class_1/','class_0/']\n",
        "        self.create_dict()\n",
        "    \n",
        "    def destination(self):\n",
        "        for i in self.test_train:\n",
        "            for j in self.classes:\n",
        "                os.makedirs(self.dest+i+j, exist_ok=True)\n",
        "                print(f'made dir = {self.dest+i+j}')\n",
        "        \n",
        "    def create_dict(self):\n",
        "        self.destination()\n",
        "        train_dir,test_dir,val_dir = self.test_train\n",
        "        class_1, class_0 = self.classes \n",
        "        src_did = self.src\n",
        "        df = meta_process()\n",
        "        y_g = df[['threshold','ID','set']].to_dict('index')\n",
        "        y_g_dict = {str(y_g[pair_key]['ID']):y_g[pair_key]for pair_key in y_g}\n",
        "        y_g_dict = {key:{**y_g_dict[key],**{'src':src_did+key+'.jpg'}} for key in y_g_dict} \n",
        "        self.y_g_dict = {key:{**y_g_dict[key], **{'dest':class_1}} if y_g_dict[key]['threshold']==1 \n",
        "                    else {**y_g_dict[key], **{'dest':class_0}} for key in y_g_dict }\n",
        "        print(len(self.y_g_dict))\n",
        "        \n",
        "\n",
        "    def copy(self, subpatch=None, move=None):\n",
        "        \n",
        "        if not self.move and self.subpatch:\n",
        "            print('exected')\n",
        "            box = f'_patch_{self.box_n}{ext}'    \n",
        "            if self.miss:\n",
        "                miss_copy = (k \n",
        "                    for i in os.scandir('data/') \n",
        "                    for j in os.scandir(i) \n",
        "                    for k in os.scandir(j))\n",
        "                for fid in tqdm(miss_copy):\n",
        "                    shutil.move(fid.path,self.root+fid.name)\n",
        "                \n",
        "            ##some process\n",
        "            for key in tqdm(y_g_dict):\n",
        "                \n",
        "                if y_g_dict[key]['set'] == 'training':\n",
        "                    self.y_g_dict[key]['fid']=root+train_dir+y_g_dict[key]['dest']+key+box\n",
        "                elif y_g_dict[key]['set'] == 'test':\n",
        "                    self.y_g_dict[key]['fid']=root+test_dir+y_g_dict[key]['dest']+key+box\n",
        "                else:\n",
        "                    self.y_g_dict[key]['fid']=root+val_dir+y_g_dict[key]['dest']+key+box\n",
        "                \n",
        "                if not os.path.isfile(self.y_g_dict[key]['fid']): \n",
        "                    print('exected')\n",
        "                    src = y_g_dict[key]['src']\n",
        "                    bbox = self.y_g_dict[key]['BBoxes'][self.box_n]\n",
        "                    self.img = read(src)[bbox[1]:bbox[3], bbox[0]:bbox[2],:]\n",
        "\n",
        "                    try:\n",
        "                        cv2.imwrite(self.y_g_dict[key]['fid'],self.img)\n",
        "                    except:\n",
        "                        print(self.y_g_dict[key]['fid'], 'not saved')\n",
        "    \n",
        "    def augment(self,  augment_type=None):\n",
        "        read = lambda fid_: cv2.cvtColor(cv2.imread(fid_), cv2.COLOR_BGR2RGB)\n",
        "        y_g_dict = self.y_g_dict\n",
        "        root = self.dest\n",
        "        ext = '.jpg'\n",
        "        train_dir,test_dir,val_dir = self.test_train\n",
        "        for key in tqdm(y_g_dict):\n",
        "            \n",
        "            if augment_type == 'zero_pad':\n",
        "                img = read(y_g_dict[key]['src'])\n",
        "                img = train_transforms(Image.fromarray(img))\n",
        "                img = np.asarray(img).astype('uint8')\n",
        "            elif augment_type == 'reflect':\n",
        "                img = read(y_g_dict[key]['src'])\n",
        "                img = train_reflect_tansform(image=img)['image']\n",
        "\n",
        "            if y_g_dict[key]['set'] == 'training':\n",
        "                y_g_dict[key]['fid']=root+train_dir+y_g_dict[key]['dest']+augment_type+key+ext\n",
        "                cv2.imwrite(y_g_dict[key]['fid'],img)\n",
        "            elif y_g_dict[key]['set'] == 'test':\n",
        "                y_g_dict[key]['fid']=root+test_dir+y_g_dict[key]['dest']+augment_type+key+ext\n",
        "                cv2.imwrite(y_g_dict[key]['fid'],img)\n",
        "            else:\n",
        "                y_g_dict[key]['fid']=root+val_dir+y_g_dict[key]['dest']+augment_type+key+ext\n",
        "                cv2.imwrite(y_g_dict[key]['fid'],img)\n",
        "        \n",
        "    def undo(self):\n",
        "        fids = [k for i in os.scandir('data/') for j in os.scandir(i) for k in os.scandir(j)]\n",
        "        dest = 'Images/images/'\n",
        "        all_ims = len(list(os.scandir(dest)))\n",
        "        print(f'there are {all_ims} ins Source')\n",
        "        for i in fids:\n",
        "            shutil.move(i.path,dest+i.name )\n",
        "        fids = [k for i in os.scandir('data/') for j in os.scandir(i) for k in os.scandir(j)]\n",
        "        all_ims = len(list(os.scandir(dest)))\n",
        "        print(f'there are {all_ims} ins Source')\n",
        "        \n",
        "\n",
        "                \n",
        "                \n",
        "    def get_patches(self):\n",
        "        self.subpach = True\n",
        "        bbox_path = '/content/A-Lamp/multi_patch_subnet/adaptive_patch_selection/output-split'\n",
        "        batches_dir = list(os.walk(bbox_path))[0][1]\n",
        "        bbox_files = {i[-2:]:[j.path for j in os.scandir(bbox_path+'/'+i)] for i in batches_dir}\n",
        "        keys = list(bbox_files.keys())\n",
        "        for key in tqdm(keys):\n",
        "            for fl in bbox_files[key]:\n",
        "                with open(fl, 'rb') as pk:\n",
        "                    if 'df' not in locals():\n",
        "                        df = pd.read_pickle(pk)\n",
        "                    else:\n",
        "                        df = df.append(pd.read_pickle(pk))\n",
        "                    \n",
        "        boxes_dict = {\n",
        "            k.split('/')[-1].split('.')[0]:{'BBoxes':v} \n",
        "            for k,v in zip(df['Filename'],df['BBoxes']) \n",
        "            }\n",
        "\n",
        "        self.y_g_dict = {\n",
        "            key:{**self.y_g_dict[key],**boxes_dict[key]} \n",
        "            for key in self.y_g_dict if key in boxes_dict\n",
        "            }\n",
        "\n",
        "pre = Pre_pipe()\n",
        "pre_args = ['reflect','zero_pad']\n",
        "pre_args = ['reflect','zero_pad']\n",
        "model_args = ['--model convit_base']\n",
        "args = ['python main.py', '--pretrained', '--batch-size 50' ,'--epochs 20', '--data-path data/', '--nb_classes 2', '--nb_classes_pre 1000']\n",
        "\n",
        "for arg in pre_args:\n",
        "    os.system('rm -rf data/')\n",
        "    pre.destination()\n",
        "    pre.move == True\n",
        "    pre.miss == False\n",
        "    print(f'Augmenting with: {arg}')\n",
        "    pre.augment(augment_type=arg)\n",
        "    for size in model_args:\n",
        "        args.insert(4, '--output_dir drive/MyDrive/0.AVA/results/'+arg+size.split(' ')[-1])\n",
        "        args.insert(3,size)\n",
        "        command = ' '.join(args)\n",
        "        print(f'Runing Process with Args : {command}')\n",
        "        run_process(process='convit', command=command)\n",
        "        args.pop(3);args.pop(4)\n",
        "\n",
        "   \n",
        "        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "made dir = data/train/class_1/\n",
            "made dir = data/train/class_0/\n",
            "made dir = data/test/class_1/\n",
            "made dir = data/test/class_0/\n",
            "made dir = data/val/class_1/\n",
            "made dir = data/val/class_0/\n",
            "255502\n",
            "255411\n",
            "255403 255403\n",
            "253030\n",
            "made dir = data/train/class_1/\n",
            "made dir = data/train/class_0/\n",
            "made dir = data/test/class_1/\n",
            "made dir = data/test/class_0/\n",
            "made dir = data/val/class_1/\n",
            "made dir = data/val/class_0/\n",
            "Augmenting with: reflect\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 64446/253030 [10:28<26:44, 117.56it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "OTBy5tCVOalB",
        "outputId": "a395cca5-6932-4c19-e07b-6d93639a934d"
      },
      "source": [
        "\n",
        "for arg in pre_args:\n",
        "    args[4]+=arg+'_'\n",
        "    print(args)\n",
        "    command = ' '.join(args)\n",
        "    print(command)\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0e187be53a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpre_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pre_args' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY8czAFO25tX"
      },
      "source": [
        "'''boxes = [0,1,2,3,4]\n",
        "for box in boxes:\n",
        "    os.system('rm -rf data/')\n",
        "    print('data' in [i.name for i in os.scandir('.')])\n",
        "    pre.box_n=box\n",
        "    pre.destination()\n",
        "    print('data' in [i.name for i in os.scandir('.')])\n",
        "    pre.miss = True\n",
        "    pre.copy()\n",
        "    args[4]='--output_dir drive/MyDrive/0.AVA/results/patch_no_'+str(box)\n",
        "    command = ' '.join(args)\n",
        "    fid = list(os.scandir('data/test/class_0/'))[1].path\n",
        "    img = cv2.imread(fid)\n",
        "    plt.imshow(img)\n",
        "    run_process(process = 'convit', command = command)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESqWrQoOJgnI"
      },
      "source": [
        "'''read = lambda fid_: cv2.cvtColor(cv2.imread(fid_), cv2.COLOR_BGR2RGB)\n",
        "for key in tqdm(pre.y_g_dict):\n",
        "    print(key)\n",
        "    fid = pre.y_g_dict[key]['src']\n",
        "    print(fid)\n",
        "\n",
        "    if 'image' in pre.y_g_dict[key]:\n",
        "        img = pre.y_g_dict[key]['image']\n",
        "        cv2.imwrite(fid,img)\n",
        "        pre.y_g_dict[key].pop('image')\n",
        "\n",
        "    else:\n",
        "        img = read(fid)\n",
        "        zero_pad_array = reflect(img=Image.fromarray(img))\n",
        "        save_image(zero_pad_array,fid)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIlTCd_elv8c"
      },
      "source": [
        " fid_ = pre.y_g_dict[list(pre.y_g_dict.keys())[5]]['src']\n",
        " read = lambda fid_: cv2.cvtColor(cv2.imread(fid_), cv2.COLOR_BGR2RGB)\n",
        " img = read(fid_)\n",
        " zero_pad_array = train_transforms(Image.fromarray(img)).permute(1,2,0)\n",
        " plt.imshow(zero_pad_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbuVOibZLEao"
      },
      "source": [
        " fid_ = pre.y_g_dict[list(pre.y_g_dict.keys())[5]]['src']\n",
        " read = lambda fid_: cv2.cvtColor(cv2.imread(fid_), cv2.COLOR_BGR2RGB)\n",
        " img = read(fid_)\n",
        " zero_pad_array = train_reflect_tansform(image=img)['image']\n",
        " plt.imshow(zero_pad_array)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}